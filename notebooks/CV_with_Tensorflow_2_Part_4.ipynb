{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_with_Tensorflow_2_Part_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPrUxEojQ4bvrresemrk68n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudhood/learning-basics/blob/main/notebooks/CV_with_Tensorflow_2_Part_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [Computer Vision: Early Stopping to Save Time and Processing Power](https://learning.oreilly.com/scenarios/computer-vision-early/9781492094432/)"
      ],
      "metadata": {
        "id": "WMfYn6v3umYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy tensorflow &> /dev/null"
      ],
      "metadata": {
        "id": "372fc4cnvHUL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The focus on this section will be on additional tools commonly used in ML to achieve better results."
      ],
      "metadata": {
        "id": "MSFl8iPNu-X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "    model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(32,32,1)),\n",
        "            tf.keras.layers.AveragePooling2D(),\n",
        "            tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'),\n",
        "            tf.keras.layers.AveragePooling2D(),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(units=120, activation='relu'),\n",
        "            tf.keras.layers.Dense(units=84, activation='relu'),\n",
        "            tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "        ])\n",
        "    return model\n",
        "\n",
        "def prepare_data(images):\n",
        "    # Normalize the image pixels\n",
        "    images  = images / 255.0\n",
        "    \n",
        "    # Add an extra dimension to the matrix\n",
        "    images = np.expand_dims(images,-1)\n",
        "\n",
        "    # Pad the images to get it into 32x32 size\n",
        "    images = np.pad(images, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "    return images"
      ],
      "metadata": {
        "id": "ZOnizVAmulhm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `EarlyStopping` callback"
      ],
      "metadata": {
        "id": "BmfD4JNPwbW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we run too many epochs, we might overfit on the training data. It would be nice to be able to stop the training when the maximum of some metric is reached. For instance, we could stop training if the accuracy stopped improving in `n` consecutive epochs. This is called the **early stopping callback**."
      ],
      "metadata": {
        "id": "rmF0vb3DvQEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Function to clean up the data and create the model\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = prepare_data(training_images)\n",
        "test_images = prepare_data(test_images)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmBe1Sj8vO00",
        "outputId": "641112f9-4dc5-4bc5-e942-37c2d5e2b5d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 6)         60        \n",
            "                                                                 \n",
            " average_pooling2d (AverageP  (None, 15, 15, 6)        0         \n",
            " ooling2D)                                                       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 16)        880       \n",
            "                                                                 \n",
            " average_pooling2d_1 (Averag  (None, 6, 6, 16)         0         \n",
            " ePooling2D)                                                     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               69240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 81,194\n",
            "Trainable params: 81,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define callback\n",
        "callback1 = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',              # for loss would be 'min'\n",
        "    min_delta=0.001,         # min. change in monitored quantity to qualify as an improvement\n",
        "    patience=5             # how many epochs to wait for\n",
        ")"
      ],
      "metadata": {
        "id": "pOfwGd9ivhKT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Gq9Sacyuv-nS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam', \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Add a high number (100) of epochs to witness early stopping\n",
        "model.fit(\n",
        "    training_images, \n",
        "    training_labels, \n",
        "    validation_data=(test_images,test_labels), \n",
        "    epochs=100, \n",
        "    callbacks=[callback1], \n",
        "    batch_size=1024\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zCA3tTCvslW",
        "outputId": "47124675-3b66-41ad-b291-561e45194b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "59/59 [==============================] - 27s 446ms/step - loss: 1.3858 - accuracy: 0.5795 - val_loss: 0.7264 - val_accuracy: 0.7386\n",
            "Epoch 2/100\n",
            "59/59 [==============================] - 22s 379ms/step - loss: 0.6200 - accuracy: 0.7689 - val_loss: 0.5762 - val_accuracy: 0.7811\n",
            "Epoch 3/100\n",
            "59/59 [==============================] - 21s 356ms/step - loss: 0.5247 - accuracy: 0.8014 - val_loss: 0.5076 - val_accuracy: 0.8079\n",
            "Epoch 4/100\n",
            "59/59 [==============================] - 21s 352ms/step - loss: 0.4725 - accuracy: 0.8258 - val_loss: 0.4718 - val_accuracy: 0.8248\n",
            "Epoch 5/100\n",
            "59/59 [==============================] - 22s 380ms/step - loss: 0.4411 - accuracy: 0.8388 - val_loss: 0.4491 - val_accuracy: 0.8346\n",
            "Epoch 6/100\n",
            "59/59 [==============================] - 21s 355ms/step - loss: 0.4133 - accuracy: 0.8506 - val_loss: 0.4266 - val_accuracy: 0.8415\n",
            "Epoch 7/100\n",
            "59/59 [==============================] - 22s 381ms/step - loss: 0.3928 - accuracy: 0.8580 - val_loss: 0.3994 - val_accuracy: 0.8552\n",
            "Epoch 8/100\n",
            "59/59 [==============================] - 21s 364ms/step - loss: 0.3747 - accuracy: 0.8654 - val_loss: 0.3888 - val_accuracy: 0.8595\n",
            "Epoch 9/100\n",
            "59/59 [==============================] - 21s 358ms/step - loss: 0.3618 - accuracy: 0.8695 - val_loss: 0.3775 - val_accuracy: 0.8652\n",
            "Epoch 10/100\n",
            "59/59 [==============================] - 22s 371ms/step - loss: 0.3486 - accuracy: 0.8751 - val_loss: 0.3734 - val_accuracy: 0.8633\n",
            "Epoch 11/100\n",
            "59/59 [==============================] - 21s 362ms/step - loss: 0.3411 - accuracy: 0.8778 - val_loss: 0.3550 - val_accuracy: 0.8737\n",
            "Epoch 12/100\n",
            "59/59 [==============================] - 36s 606ms/step - loss: 0.3325 - accuracy: 0.8804 - val_loss: 0.3529 - val_accuracy: 0.8731\n",
            "Epoch 13/100\n",
            "59/59 [==============================] - 28s 476ms/step - loss: 0.3214 - accuracy: 0.8851 - val_loss: 0.3514 - val_accuracy: 0.8733\n",
            "Epoch 14/100\n",
            "59/59 [==============================] - 27s 454ms/step - loss: 0.3152 - accuracy: 0.8873 - val_loss: 0.3358 - val_accuracy: 0.8813\n",
            "Epoch 15/100\n",
            "59/59 [==============================] - 26s 441ms/step - loss: 0.3081 - accuracy: 0.8893 - val_loss: 0.3362 - val_accuracy: 0.8802\n",
            "Epoch 16/100\n",
            "59/59 [==============================] - 26s 439ms/step - loss: 0.3054 - accuracy: 0.8899 - val_loss: 0.3283 - val_accuracy: 0.8830\n",
            "Epoch 17/100\n",
            "59/59 [==============================] - 22s 375ms/step - loss: 0.2980 - accuracy: 0.8926 - val_loss: 0.3225 - val_accuracy: 0.8842\n",
            "Epoch 18/100\n",
            "59/59 [==============================] - 21s 360ms/step - loss: 0.2950 - accuracy: 0.8933 - val_loss: 0.3210 - val_accuracy: 0.8849\n",
            "Epoch 19/100\n",
            "21/59 [=========>....................] - ETA: 12s - loss: 0.2927 - accuracy: 0.8962"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot\n",
        "Observe that model accuracy starts to decrease after reaching the maximum. The early stopping callback allowed the model to stop at that point."
      ],
      "metadata": {
        "id": "t4z9Df4lwO73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model.history.history['accuracy'],label='Train Accuracy')\n",
        "plt.plot(model.history.history['val_accuracy'],label='Test Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "# plt.savefig('accuracy_plot_1.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "73gO11vov7cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.close()\n",
        "plt.plot(model.history.history['loss'],label='Train Loss')\n",
        "plt.plot(model.history.history['val_loss'],label='Test Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "# plt.savefig('loss_plot_1.png')\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "M6aeen1QwEnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## `LearningRateScheduler` Callback\n",
        "Every optimizer has a `learning_rate` argument:\n",
        "* Too low = takes more epochs to achieve a good accuracy\n",
        "* Too high - will overshoot the minimum and just oscillate around poor values of acuracy.\n",
        "\n",
        "Another way is to fix it to a medium-high value and reduce it on each epoch. This results in large steps towards the minimum in the start but much slower steps after a while. We can do this using the `LearningRateScheduler` callback."
      ],
      "metadata": {
        "id": "BOacMqy4wYPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = prepare_data(training_images)\n",
        "test_images = prepare_data(test_images)\n",
        "\n",
        "model = create_model()\n",
        "\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "_FD9rp_hwNfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scheduler function that reduces the learning rate by a factor of e^-0.1.\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 5:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * tf.math.exp(-0.1)\n",
        "\n",
        "callback2 = tf.keras.callbacks.LearningRateScheduler(\n",
        "    schedule=scheduler,  # Takes epoch index and current learning rate as args, returns a new learning rate as float.\n",
        "    verbose=1            # 0 = quiet, 1 = update messages\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "vy5vwMaFw-af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "vhzOoBuYxLO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    training_images, \n",
        "    training_labels, \n",
        "    validation_data=(test_images,test_labels), \n",
        "    epochs=30, \n",
        "    callbacks=[callback2], \n",
        "    batch_size=1024\n",
        ")"
      ],
      "metadata": {
        "id": "2lSgGHofxKBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "QoMf-RKFxOWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(model.history.history['accuracy'],label='Train Accuracy')\n",
        "plt.plot(model.history.history['val_accuracy'],label='Test Accuracy')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "# plt.savefig('accuracy_plot_2.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mxoYaAMhxPWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.close()\n",
        "plt.plot(model.history.history['loss'],label='Train Loss')\n",
        "plt.plot(model.history.history['val_loss'],label='Test Loss')\n",
        "plt.legend()\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "# plt.savefig('loss_plot_2.png')\n",
        "plot.show()"
      ],
      "metadata": {
        "id": "fyFqtfqZxbnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r2SEFkSgxdFE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}